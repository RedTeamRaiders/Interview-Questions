Authored by **Kalyan KS**. You can follow him on [Twitter](https://x.com/kalyan_kpl) and [LinkedIn](https://www.linkedin.com/in/kalyanksnlp/) for the latest LLM, RAG and Agent updates.

## ðŸ“Œ Q76: Given a retrieval result, show how to manually calculate the MAP@5 (Mean Average Precision at 5). What does MAP reveal about the retrieval system that raw Precision does not?

### âœ… Answer

To manually calculate MAP@5, list the top 5 retrieved items for each query and note the positions where relevant items appear; then, compute precision at each relevant position (e.g., if the first relevant item appears at rank 2, precision = 1/2) and average these values to get the Average Precision (AP) for that query. Repeat this for all queries and take the mean of their APs for MAP@5.

MAP@5 reveals a retrieval system's ability to rank relevant items higher. In contrast, raw Precision only measures the proportion of relevant items retrieved, ignoring their order. This makes MAP@5 a better indicator of how well the system prioritizes relevance at the top of the result list.

## ðŸ“Œ Q77: If all the relevant chunks are at the very bottom, how would this affect MRR, MAP, and NDCG metrics? Explain each.

### âœ… Answer

If all relevant chunks are at the bottom of a ranked list for a search query, MRR (Mean Reciprocal Rank) would be low, as it measures the reciprocal of the rank of the first relevant chunk. MAP (Mean Average Precision) would also be low, as it averages precision across all relevant chunks, penalizing late appearances heavily due to increasing denominators in precision calculations. 

NDCG (Normalized Discounted Cumulative Gain) would similarly be low, as it discounts the relevance scores of chunks appearing later in the ranking, reducing the cumulative gain. 

## ðŸ“Œ Q78: Suppose your RAG retriever gets perfect Recall@10 but low Precision@10. What problems could this cause for the downstream generator?

### âœ… Answer

Perfect Recall@10 means all relevant chunks are retrieved within the top 10 results. Low Precision@10 indicates many of those retrieved chunks are irrelevant. If a RAG retriever achieves perfect Recall@10 but low Precision@10, the downstream generator receives all the relevant information mixed with much irrelevant content. 

This will confuse the generator model and increase the chance of generating off-topic or inaccurate responses. 

## LLM Survey Papers Collection

ðŸ‘‰ [Repo Link](https://github.com/KalyanKS-NLP/LLM-Survey-Papers-Collection)

![LLM Survey Papers Collection](images/llm-survey-papers-collection.jpg)

---------------------------------------------------------------------------------------------




