Authored by **Kalyan KS**. You can follow him on [Twitter](https://x.com/kalyan_kpl) and [LinkedIn](https://www.linkedin.com/in/kalyanksnlp/) for the latest LLM, RAG and Agent updates.

## ğŸ“Œ Q4: What are effective strategies to reduce latency in RAG systems?

### âœ… Answer

Caching, embedding quantization, selective query rewriting, and selective re-ranking are some of the ways to reduce RAG latency. Caching stores retrieved results or generated responses to avoid redundant computation. Embedding quantization to lower bit precision reduces memory and computational load, speeding up retrieval. 

Selective query rewriting enhances recall and relevance by refining queries prior to retrieval, primarily utilized for complex or ambiguous queries. Selective re-ranking is only used for complicated queries, which cuts down on unnecessary computation for simpler ones. 


## ğŸ“Œ Q5: Explain R, A, and G in RAG. 

### âœ… Answer

RAG stands for Retrieval-Augmented Generation. The "R" or Retrieval, refers to the process of searching and fetching the most relevant information from external knowledge sources for the given user query. 

The "A" or Augmented, involves including the retrieved relevant context in the LLM prompt having the user query and instructions so that the LLM can generate a response based on the provided context.  

Finally, the "G" or Generation is the phase during which the generator LLM processes the prompt having instructions, a query, and context to generate a response that is coherent, accurate, and contextually relevant. 


## ğŸ“Œ Q6: How does RAG help reduce hallucinations in LLM generated responses?

### âœ… Answer

Without RAG, LLM answers user questions based on what it learned from the training corpus, which may not be up-to-date or complete. This could lead to hallucinated responses, which are answers that sound right but are wrong.

Retrieval-Augmented Generation (RAG) helps cut down on hallucinations in LLM-generated responses by adding an external retrieval system that pulls relevant, factual information from trusted, up-to-date external knowledge sources.

By combining retrieval with generation, RAG ensures that answers are more accurate, contextually relevant, and less prone to fabrications or false information, significantly enhancing the reliability of the output. 


## **ğŸš€ AIxFunda Newsletter (free)**

Join ğŸš€ AIxFunda free newsletter to get the latest updates and interesting tutorials related to Generative AI, LLMs, Agents and RAG.

- âœ¨ Weekly GenAI updates.
- ğŸ“„ Weekly LLM, Agents and RAG paper updates.
- ğŸ“ 1 fresh blog post on an interesting topic every week.

ğŸ‘‰ [Subcribe Now](https://aixfunda.substack.com/) 

---------------------------------------------------------------------------------------------






