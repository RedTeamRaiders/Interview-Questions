Authored by **Kalyan KS**. You can follow him on [Twitter](https://x.com/kalyan_kpl) and [LinkedIn](https://www.linkedin.com/in/kalyanksnlp/) for the latest LLM, RAG and Agent updates.

## ğŸ“Œ Q103: The generatorâ€™s response mentions facts not present in the retrieved context. Describe how faithfulness and response relevancy metrics would be impacted.

### âœ… Answer

The faithfulness metric measures the proportion of claims in the response that are backed up by context. Therefore, the score will decrease if the LLM-generated answer contains unsupported claims.

In the case of the Response Relevancy metric, the score will decrease only if the unsupported facts are irrelevant to the user query. Otherwise, the score will remain high.

This underscores a key difference between these two metrics: Faithfulness metric looks for answerâ€™s factual consistency with the context, while Response Relevancy assesses answerâ€™s relevancy with the query.

## ğŸ“Œ Q104: How does the Response Relevancy metric help evaluate whether a RAG generator is addressing the userâ€™s query effectively?

### âœ… Answer

The Response Relevancy metric is computed as the ratio of relevant statements in the response to the total number of statements. So, this metric checks the effectiveness of the RAG generator by measuring how well the response aligns with the user query.

A score close to 1 means the answer directly addresses the query with little to no irrelevant content. A score close to 0 means that the answer contains information that is not related to the question.  

## ğŸ“Œ Q105: When evaluating RAG generator output, what are the risks of relying solely on response relevancy? How can including the faithfulness metric improve reliability?

### âœ… Answer

The Response Relevancy metric tells you how relevant the answer is to the user query. But this metric doesn't check if the answer is based on the retrieved context, so it misses factual errors.

The faithfulness metric is the number of supported claims divided by the total number of claims. Adding the faithfulness metric makes the system more reliable by making sure that the claims in the LLM-generated response are supported by the context.
  
This dual evaluation ensures the RAG system delivers both relevant and factual responses, reducing the risk of misleading outputs.


## **ğŸ‘¨ğŸ»â€ğŸ’» LLM Engineer Toolkit**

ğŸ¤– This repository contains a curated list of 120+ LLM, RAG and Agent related libraries category wise. 

ğŸ‘‰ [Repo link](https://github.com/KalyanKS-NLP/llm-engineer-toolkit) 

This repository is highly useful for Data Scientists, AI/ML Engineers working with LLMs, RAG and Agents.

![LLM Engineer Toolkit](images/llm-engineer-toolkit.jpg)
 

---------------------------------------------------------------------------------------------




