Authored by **Kalyan KS**. You can follow him on [Twitter](https://x.com/kalyan_kpl) and [LinkedIn](https://www.linkedin.com/in/kalyanksnlp/) for the latest LLM, RAG and Agent updates.

## ğŸ“Œ Q100: Why might a RAG system with perfect Context Recall still fail to produce accurate responses? How does the Faithfulness metric help diagnose this issue?

### âœ… Answer

Context recall evaluates the completeness of the retrieved context in a RAG pipeline. Perfect Context Recall means the retrieved context includes all the ground truth claims.  A RAG system with perfect Context Recall may still fail to produce accurate responses. This happens when the generator hallucinates and  includes claims unsupported by the retrieved context. 

The Faithfulness metric helps diagnose this issue by measuring how many claims in the generated response are factually supported by the retrieved context. A low or moderate faithfulness metric score indicates a less accurate response, i.e., the response includes unsupported claims.  

## ğŸ“Œ Q101: Explain how hallucinations in LLMs specifically impact the Faithfulness metric. What techniques could you implement to improve the Faithfulness metric score?

### âœ… Answer

The faithfulness metric measures the proportion of claims in the response that are backed up by context.  Hallucinations reduce the faithfulness metric score by introducing unsupported claims in the generated response. These unsupported claims either contradict or have no basis in the provided context.

To improve Faithfulness scores, techniques such as incorporating natural language inference (NLI) or fact-checking models to verify claims, using prompt engineering to discourage unsupported generation, etc., can be used.

## ğŸ“Œ Q102:  How does Response Relevancy differ from Context Relevancy, and why do you need both metrics to properly evaluate a RAG system? 

### âœ… Answer

Response Relevancy measures how well a RAG system's generated response aligns with the userâ€™s query by calculating the ratio of relevant statements in the response to the total statements. Context Relevancy evaluates the relevance of retrieved context to the query by measuring the proportion of relevant statements in the context. 

Both metrics are essential because Context Relevancy ensures the retriever fetches relevant context, while Response Relevancy verifies that the generator produces an answer directly addressing the query. 

A RAG system could retrieve relevant context but generate an off-topic response, or vice versa. Hence, evaluating both ensures the entire RAG pipelineâ€”retrieval and generationâ€”performs effectively. 

**â˜• Support the Author**
-------------------------------------------------------------------------------------------
I hope you found this â€œRAG Interview Questions and Answers Hubâ€  highly useful.  

Iâ€™ve made this freely available to help the AI and NLP community grow and to support learners like you. If you found it helpful and would like to show your appreciation, you can buy me a coffee to keep me motivated in creating more free resources like this.

ğŸ‘‰ [Buy Me a Coffee](https://ko-fi.com/kalyanksnlp)

Your small gesture goes a long way in supporting my workâ€”thank you for being part of this journey! ğŸ™

â€” Kalyan KS

---------------------------------------------------------------------------------------------





