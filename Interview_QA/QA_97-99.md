Authored by **Kalyan KS**. You can follow him on [Twitter](https://x.com/kalyan_kpl) and [LinkedIn](https://www.linkedin.com/in/kalyanksnlp/) for the latest LLM, RAG and Agent updates.

## ğŸ“Œ Q97: How does the Faithfulness metric assess the quality of a RAG generator?

### âœ… Answer

The Faithfulness metric assesses the quality of a RAG generator by measuring how factually consistent the generated response is with the retrieved context. It is computed as the ratio of claims in the response that are supported by the retrieved context to the total number of claims.  

A score of 1 indicates all claims are fully supported, reflecting high factual accuracy. A score of 0 shows no claims are supported, indicating complete factual inconsistency. This metric ensures the RAG system generates reliable and contextually grounded responses.

## ğŸ“Œ Q98: Distinguish between Faithfulness and Context Precision metrics in RAG evaluation. Why might a system have high Context Precision but low Faithfulness, and what would this indicate about your pipeline?

### âœ… Answer

Faithfulness measures how factually consistent a RAG generatorâ€™s response is with the retrieved context. This metric is computed as the ratio of supported claims to total claims in the response. The Context Precision metric focuses on the prioritization of relevant information by evaluating how well a retriever ranks relevant chunks within the top K. 

A system might have high Context Precision but low Faithfulness if the retriever effectively ranks relevant chunks highly, but the generator introduces unsupported or contradictory claims not grounded in the context. This indicates a strong retrieval stage but a flawed generation stage, where the model fails to accurately interpret or utilize the retrieved information.

## ğŸ“Œ Q99: A RAG system has high context precision but low faithfulness. How would you address this?

### âœ… Answer

A RAG system with high context precision and low faithfulness happens when the retriever is selecting relevant chunks accurately, but the generator is producing responses with unsupported claims. To address this, one should focus on improving the generatorâ€™s grounding and claim verification processes.

Use stronger cross-checking mechanisms like natural language inference models or fact-checking modules against the retrieved context. Additionally, tuning the generation prompts to encourage reliance on the context can help increase faithfulness. 

## **ğŸ‘¨ğŸ»â€ğŸ’» Prompt Engineering Techniques Hub**

This GitHub repo includes implementations of must know 25+ prompt engineering techniques.

ğŸ‘‰ [Repo link](https://github.com/KalyanKS-NLP/Prompt-Engineering-Techniques-Hub)

Knowledge of prompt engineering techniques is essential for Data Scientists, AI/ML Engineers working with LLMs, RAG and Agents. 

![Prompt Engineering Techniques Hub](images/prompt-eng-techniques-hub.jpg)
 

------------------------------------------------------------------------------------------





