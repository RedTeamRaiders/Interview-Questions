Authored by **Kalyan KS**. You can follow him on [Twitter](https://x.com/kalyan_kpl) and [LinkedIn](https://www.linkedin.com/in/kalyanksnlp/) for the latest LLM, RAG and Agent updates.

## ğŸ“Œ Q85: Explain the possible reasons for a RAG retrieval system with consistently low context precision. 

### âœ… Answer

Context Precision is computed as the weighted sum of Precision@k, normalized by the number of relevant chunks. So low Context Precision@k scores reflect the presence of high proportion of irrelevant chunks or poor ranking of relevant chunks within the top K results. 

This could stem from ineffective query understanding, where the system misinterprets the userâ€™s intent, or a poorly designed retrieval algorithm that fails to prioritize chunks matching the ground truth. Additionally, a noisy or low-quality document corpus might contain few relevant chunks, causing irrelevant ones to dominate the retrieved set. 

## ğŸ“Œ Q86: Compare Context Recall with traditional information retrieval recall. Why is Context Recall computed using "ground truth claims" rather than simply counting relevant documents?

### âœ… Answer

Context Recall in RAG retrieval differs from traditional information retrieval recall by focusing on the completeness of information through ground truth claims rather than merely counting relevant documents. 

While traditional recall counts how many relevant documents are retrieved, Context Recall decomposes the reference answer into individual claims and checks if these specific claims are found in the retrieved context. 

This approach ensures a more fine-grained evaluation of whether all necessary pieces of information required to answer the query are present in the context or not. 

## ğŸ“Œ Q87: What does context precision measure in a RAG retriever, and how does it differ from context recall?

### âœ… Answer

Context Precision in a RAG retriever measures how well the system ranks relevant chunks of information higher than irrelevant ones within the retrieved context, emphasizing the prioritization of useful data. In contrast, Context Recall assesses the completeness of the retrieved context, evaluating whether all the relevant pieces of information necessary to answer the query are present. 

Together, they provide complementary insights: context precision ensures useful information is prioritized, whereas context recall ensures that no important information is missed.


## **ğŸ‘¨ğŸ»â€ğŸ’» Prompt Engineering Techniques Hub**

This GitHub repo includes implementations of must know 25+ prompt engineering techniques.

ğŸ‘‰ [Repo link](https://github.com/KalyanKS-NLP/Prompt-Engineering-Techniques-Hub)

Knowledge of prompt engineering techniques is essential for Data Scientists, AI/ML Engineers working with LLMs, RAG and Agents. 

![Prompt Engineering Techniques Hub](images/prompt-eng-techniques-hub.jpg)
 

------------------------------------------------------------------------------------------





