Authored by **Kalyan KS**. You can follow him on [Twitter](https://x.com/kalyan_kpl) and [LinkedIn](https://www.linkedin.com/in/kalyanksnlp/) for the latest LLM, RAG and Agent updates.

## ğŸ“Œ Q19: What are the popular frameworks to implement a RAG system? Justify your choice of framework.

### âœ… Answer

LangChain, LlamaIndex, and Haystack are the most popular frameworks for RAG implementation. LangChain is great for custom pipelines, and LlamaIndex is great for efficient document indexing and retrieval. The Haystack framework provides excellent modularity for building RAG systems.

I would recommend LangChain because of its comprehensive ecosystem, extensive documentation, active community support, and flexibility in handling various data sources and LLM integrations.

## ğŸ“Œ Q20: Explain the influence of LLM context window size on RAG hyperparameters.

### âœ… Answer

The size of the LLM context window has a big impact on RAG hyperparameters, like chunk size and the number of chunks that are retrieved. Larger context windows let you feed more retrieved chunks to the LLM, which increases the chance of including more relevant information. This could make the quality of the generated answers better. 

But after a certain point, performance gains start to go down because of problems like "lost in the middle" and higher latency.

## ğŸ“Œ Q21: How do you choose values for various LLM inference hyperparameters in a RAG system?

### âœ… Answer

Temperature controls randomnessâ€”lower values give more focused and deterministic responses suitable for technical or precise tasks, while higher values make output more creative and diverse. 

The max tokens limit the length of the output, making sure that the answers are short or long enough depending on the use case, with a trade-off between completeness and latency. Optimal settings depend on the specific application context and are found through iterative experimentation. 

## **ğŸ‘¨ğŸ»â€ğŸ’» Prompt Engineering Techniques Hub**

This GitHub repo includes implementations of must know 25+ prompt engineering techniques.

ğŸ‘‰ [Repo link](https://github.com/KalyanKS-NLP/Prompt-Engineering-Techniques-Hub)

Knowledge of prompt engineering techniques is essential for Data Scientists, AI/ML Engineers working with LLMs, RAG and Agents. 

![Prompt Engineering Techniques Hub](images/prompt-eng-techniques-hub.jpg)
 

------------------------------------------------------------------------------------------






